{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def predictpr(fitted, feature_test):\n",
    "    '''\n",
    "    This function predicts the probability of response 1 for the test dataset.\n",
    "    \n",
    "    fitted: fitted classifier\n",
    "    feature_test: feature set in test data\n",
    "    \n",
    "    return: predictions\n",
    "    '''\n",
    "    return fitted.predict_proba(feature_test)[:,1]\n",
    "\n",
    "def knn_score(x_train, y_train, x_test, n, weights = 'uniform', distance_metric = 'minkowski', p=2):\n",
    "    '''\n",
    "    This function builds a KNN classifier.\n",
    "    \n",
    "    x_train: training set with features\n",
    "    y_train: training set with labels\n",
    "    n: number of neighbors\n",
    "    weights: weight function used in prediction.\n",
    "    distance_metric: the distance metric to use\n",
    "    p: Power parameter for the Minkowski metric. \n",
    "    \n",
    "    returns: fitted KNN classifier\n",
    "    '''\n",
    "    if distance_metric == 'minkowski':\n",
    "        knn = KNeighborsClassifier(n_neighbors=n, weights = weights, p=p, metric= distance_metric)\n",
    "        \n",
    "    else:\n",
    "        knn =KNeighborsClassifier(n_neighbors=n, weights = weights, metric= distance_metric)\n",
    "    \n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    return predictpr(knn, x_test)\n",
    "\n",
    "#can use existing prediction function to predict scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def lr_score(x_train, y_train, x_test, p = 'l1', c = 1.0, solver = 'liblinear', seed=12345):\n",
    "    '''\n",
    "    This function builds a Logistic Regression model.\n",
    "    \n",
    "    x_train: training set with features\n",
    "    y_train: training set with labels\n",
    "    p: penalty (l1 or l2)\n",
    "    c: Inverse of regularization strength; must be a positive float.\n",
    "    solver: Algorithm to use in the optimization problem.\n",
    "    seed: random seed\n",
    "    \n",
    "    returns fitted Logistic Regression\n",
    "    '''\n",
    "    \n",
    "    lr = LogisticRegression(penalty = p, C = c, solver= solver, random_state = seed)\n",
    "    lr.fit(x_train, y_train)\n",
    "    \n",
    "    return predictpr(lr, x_test)\n",
    "\n",
    "\n",
    "#can use existing prediction function to predict scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def linsvc_score(x_train, y_train, x_test, p = 'l2', c = 1.0, seed = 12345):\n",
    "    '''\n",
    "    This function builds a fitted linear SVC\n",
    "    \n",
    "    x_train: training set with features\n",
    "    y_train: training set with labels\n",
    "    p: penalty (l2)\n",
    "    c: Penalty parameter C of the error term\n",
    "    seed: random seed\n",
    "    \n",
    "    returns fitted linear SVC\n",
    "    '''\n",
    "    \n",
    "    lsvc = LinearSVC(penalty = p, C=c, random_state=seed)\n",
    "    lsvc.fit(x_train, y_train)\n",
    "    \n",
    "    return lsvc.decision_function(x_test)\n",
    "\n",
    "def svm_score(fitted_lsvc, x_test):\n",
    "    '''\n",
    "    This function uses a test set to make scores using Linear SVC.\n",
    "    \n",
    "    fitted_lsvc: fitted Linear SVC\n",
    "    x_test: test set with features\n",
    "    \n",
    "    returns predictions\n",
    "    '''\n",
    "    return fitted_lsvc.decision_function(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "def accuracy_at_threshold(y_test, pred_scores, thresh =0.5):\n",
    "    '''\n",
    "    This function calculates that accuracy of model given a threshold\n",
    "\n",
    "    y_test: real labels\n",
    "    pred: prediction scores\n",
    "    threshold: threshold for predictions\n",
    "\n",
    "    returns accuracy \n",
    "    '''\n",
    "    pred_one = [1 if x >= thresh else 0 for x in pred_scores]\n",
    "    \n",
    "    return metrics.accuracy_score(y_test, pred_one)\n",
    "\n",
    "def build_cmatrix(y_test, pred_scores, threshold):\n",
    "    '''\n",
    "    This function builds a confusion matrix for a given threshold\n",
    "    \n",
    "    pred_scores: prediction scores\n",
    "    y_test: real labels\n",
    "    threshold: threshold for predictions\n",
    "    \n",
    "    returns tuple (true_negatives, false_positive, false_negatives, true_positives)\n",
    "    '''\n",
    "    pred = [1 if x >= threshold else 0 for x in pred_scores]\n",
    "    \n",
    "    cmatrix = confusion_matrix(y_test, pred)\n",
    "    \n",
    "    true_negatives, false_positive, false_negatives, true_positives = cmatrix.ravel()\n",
    "\n",
    "    return (true_negatives, false_positive, false_negatives, true_positives)\n",
    "\n",
    "def precision_at_threshold(y_test, pred_scores, thresh =0.5):\n",
    "    '''\n",
    "    This function calculates precision of model given a threshold\n",
    "\n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    threshold: threshold for predictions\n",
    "\n",
    "    returns precision\n",
    "    '''\n",
    "    pred_one = [1 if x >= thresh else 0 for x in pred_scores]\n",
    "    \n",
    "    return metrics.precision_score(y_test, pred_one)\n",
    "\n",
    "def recall_at_threshold(y_test, pred_scores, thresh =0.5):\n",
    "    '''\n",
    "    This function calculates recall of model given a threshold\n",
    "\n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    threshold: threshold for predictions\n",
    "\n",
    "    returns recall\n",
    "    '''\n",
    "    pred_one = [1 if x >= thresh else 0 for x in pred_scores]\n",
    "    \n",
    "    return metrics.recall_score(y_test, pred_one)\n",
    "\n",
    "def f1_at_threshold(y_test, pred_scores, thresh =0.5):\n",
    "    '''\n",
    "    This function calculates that accuracy of model given a threshold\n",
    "\n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    threshold: threshold for predictions\n",
    "\n",
    "    returns f1 score \n",
    "    '''\n",
    "    pred_one = [1 if x >= thresh else 0 for x in pred_scores]\n",
    "    \n",
    "    return metrics.f1_score(y_test, pred_one)\n",
    "\n",
    "def auc_roc(y_test, pred_scores):\n",
    "    '''\n",
    "    This function calculates the area under the ROC curve\n",
    "    \n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    \n",
    "    returns auc\n",
    "    '''\n",
    "    \n",
    "    return metrics.roc_auc_score(y_test, pred_scores)\n",
    "\n",
    "def plot_precision_recall(y_test, pred_scores):\n",
    "    '''\n",
    "    This function plots the precision recall curve\n",
    "    \n",
    "    y_test: true labels\n",
    "    pred_scores: predicted scores\n",
    "    \n",
    "    return: none\n",
    "    '''\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, pred_scores)\n",
    "    plt.pyplot.plot(recall, precision, marker='.')\n",
    "    plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_pipeline as pp\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "file = './data/projects_2012_2013.csv'\n",
    "df = pp.load_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for hw3 specific data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert date columns to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date_posted = pp.col_datetime(df, 'date_posted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.datefullyfunded = pp.col_datetime(df,'datefullyfunded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pp.create_label(df, pred_time=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_charter</th>\n",
       "      <th>school_magnet</th>\n",
       "      <th>primary_focus_subject</th>\n",
       "      <th>primary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Civics &amp; Government</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>2012-04-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suburban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_metro school_charter school_magnet primary_focus_subject  \\\n",
       "0        urban              f             f           Mathematics   \n",
       "1        urban              f             f   Civics & Government   \n",
       "2        urban              f             f              Literacy   \n",
       "3        urban              f             t              Literacy   \n",
       "4     suburban              f             f              Literacy   \n",
       "\n",
       "    primary_focus_area resource_type    poverty_level    grade_level  \\\n",
       "0       Math & Science      Supplies  highest poverty  Grades PreK-2   \n",
       "1     History & Civics         Books  highest poverty     Grades 3-5   \n",
       "2  Literacy & Language    Technology     high poverty     Grades 3-5   \n",
       "3  Literacy & Language         Books     high poverty  Grades PreK-2   \n",
       "4  Literacy & Language    Technology     high poverty  Grades PreK-2   \n",
       "\n",
       "   total_price_including_optional_support  students_reached  \\\n",
       "0                                 1498.61              31.0   \n",
       "1                                  282.47              28.0   \n",
       "2                                 1012.38              56.0   \n",
       "3                                  175.33              23.0   \n",
       "4                                 3591.11             150.0   \n",
       "\n",
       "  eligible_double_your_impact_match date_posted  label  \n",
       "0                                 f  2013-04-14      1  \n",
       "1                                 t  2012-04-07      1  \n",
       "2                                 f  2012-01-30      0  \n",
       "3                                 f  2012-10-11      1  \n",
       "4                                 f  2013-01-08      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols=['school_metro','school_charter', 'school_magnet', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'total_price_including_optional_support', 'students_reached', 'eligible_double_your_impact_match', 'date_posted', 'label']\n",
    "sel = df[feature_cols].copy()\n",
    "sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify feature columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_metro\n",
      "primary_focus_subject\n",
      "primary_focus_area\n",
      "resource_type\n",
      "grade_level\n",
      "students_reached\n"
     ]
    }
   ],
   "source": [
    "for x in pp.na_col(df):\n",
    "    if x in feature_cols:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing categorical variables with the most frequent, which is a common way to handle missing categorical data without more information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['school_metro','primary_focus_subject','primary_focus_area','resource_type','grade_level']\n",
    "for x in cat_cols:\n",
    "    sel = pp.na_fill_col(sel, x , pp.most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing numerical variable (students_reached) with the median value because there are outliers affecting the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10       18.0\n",
       "0.25       23.0\n",
       "0.50       30.0\n",
       "0.75      100.0\n",
       "0.90      200.0\n",
       "0.98      700.0\n",
       "1.00    12143.0\n",
       "Name: students_reached, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.students_reached.quantile([0.1, 0.25, 0.5, 0.75, 0.9,0.98,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = pp.na_fill_col(sel, 'students_reached', np.nanmedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that there are no more missing values in feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in pp.na_col(sel):\n",
    "    if x in feature_cols:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretize numeric features and then get all dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30.0, 100.0], (23.0, 30.0], (0.999, 23.0], (100.0, 12143.0]]\n",
       "Categories (4, interval[float64]): [(0.999, 23.0] < (23.0, 30.0] < (30.0, 100.0] < (100.0, 12143.0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# discretize numeric features\n",
    "bucketdict= {'total_price_including_optional_support': 4, 'students_reached':4}\n",
    "df_discr = pp.feat_mult_disc(sel, bucketdict, qt=True)\n",
    "\n",
    "df_discr.total_price_including_optional_support_binned.unique()\n",
    "df_discr.students_reached_binned.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_binary = list(df_discr.columns)\n",
    "col_to_binary.remove('label')\n",
    "col_to_binary.remove('date_posted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school_metro',\n",
       " 'school_charter',\n",
       " 'school_magnet',\n",
       " 'primary_focus_subject',\n",
       " 'primary_focus_area',\n",
       " 'resource_type',\n",
       " 'poverty_level',\n",
       " 'grade_level',\n",
       " 'eligible_double_your_impact_match',\n",
       " 'total_price_including_optional_support_binned',\n",
       " 'students_reached_binned']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_posted</th>\n",
       "      <th>label</th>\n",
       "      <th>school_metro_rural</th>\n",
       "      <th>school_metro_suburban</th>\n",
       "      <th>school_metro_urban</th>\n",
       "      <th>school_charter_f</th>\n",
       "      <th>school_charter_t</th>\n",
       "      <th>school_magnet_f</th>\n",
       "      <th>school_magnet_t</th>\n",
       "      <th>primary_focus_subject_Applied Sciences</th>\n",
       "      <th>...</th>\n",
       "      <th>eligible_double_your_impact_match_f</th>\n",
       "      <th>eligible_double_your_impact_match_t</th>\n",
       "      <th>total_price_including_optional_support_binned_(91.999, 345.81]</th>\n",
       "      <th>total_price_including_optional_support_binned_(345.81, 510.5]</th>\n",
       "      <th>total_price_including_optional_support_binned_(510.5, 752.96]</th>\n",
       "      <th>total_price_including_optional_support_binned_(752.96, 164382.84]</th>\n",
       "      <th>students_reached_binned_(0.999, 23.0]</th>\n",
       "      <th>students_reached_binned_(23.0, 30.0]</th>\n",
       "      <th>students_reached_binned_(30.0, 100.0]</th>\n",
       "      <th>students_reached_binned_(100.0, 12143.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_posted  label  school_metro_rural  school_metro_suburban  \\\n",
       "0  2013-04-14      1                   0                      0   \n",
       "1  2012-04-07      1                   0                      0   \n",
       "2  2012-01-30      0                   0                      0   \n",
       "3  2012-10-11      1                   0                      0   \n",
       "4  2013-01-08      0                   0                      1   \n",
       "\n",
       "   school_metro_urban  school_charter_f  school_charter_t  school_magnet_f  \\\n",
       "0                   1                 1                 0                1   \n",
       "1                   1                 1                 0                1   \n",
       "2                   1                 1                 0                1   \n",
       "3                   1                 1                 0                0   \n",
       "4                   0                 1                 0                1   \n",
       "\n",
       "   school_magnet_t  primary_focus_subject_Applied Sciences  ...  \\\n",
       "0                0                                       0  ...   \n",
       "1                0                                       0  ...   \n",
       "2                0                                       0  ...   \n",
       "3                1                                       0  ...   \n",
       "4                0                                       0  ...   \n",
       "\n",
       "   eligible_double_your_impact_match_f  eligible_double_your_impact_match_t  \\\n",
       "0                                    1                                    0   \n",
       "1                                    0                                    1   \n",
       "2                                    1                                    0   \n",
       "3                                    1                                    0   \n",
       "4                                    1                                    0   \n",
       "\n",
       "   total_price_including_optional_support_binned_(91.999, 345.81]  \\\n",
       "0                                                  0                \n",
       "1                                                  1                \n",
       "2                                                  0                \n",
       "3                                                  1                \n",
       "4                                                  0                \n",
       "\n",
       "   total_price_including_optional_support_binned_(345.81, 510.5]  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   total_price_including_optional_support_binned_(510.5, 752.96]  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   total_price_including_optional_support_binned_(752.96, 164382.84]  \\\n",
       "0                                                  1                   \n",
       "1                                                  0                   \n",
       "2                                                  1                   \n",
       "3                                                  0                   \n",
       "4                                                  1                   \n",
       "\n",
       "   students_reached_binned_(0.999, 23.0]  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      1   \n",
       "4                                      0   \n",
       "\n",
       "   students_reached_binned_(23.0, 30.0]  \\\n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   students_reached_binned_(30.0, 100.0]  \\\n",
       "0                                      1   \n",
       "1                                      0   \n",
       "2                                      1   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   students_reached_binned_(100.0, 12143.0]  \n",
       "0                                         0  \n",
       "1                                         0  \n",
       "2                                         0  \n",
       "3                                         0  \n",
       "4                                         1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn variables into dummies\n",
    "df_final = pp.feat_binary(df_discr, col_to_binary)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run variations of models: \n",
    "### Decision trees, KNN, Logistic Regression, Linear SVM, Random forests, Bagging, Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [dt.datetime(2012,1,1), dt.datetime(2012,7,1), dt.datetime(2013,1,1), dt.datetime(2013,7,1), dt.datetime(2014,1,1)]\n",
    "pred_time = 60 #days\n",
    "label_col = 'label'\n",
    "split_col = 'date_posted'\n",
    "feature_cols= list(df_final.columns)\n",
    "feature_cols.remove('label')\n",
    "feature_cols.remove('date_posted')\n",
    "seed=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {'type': 'Dtree', 'clf': pp.dtree_score, 'criteria': ['entropy', 'gini'], 'depth': [10,20,30],'min_leaf': [100, 300,500], 'seed': seed},\n",
    "    {'type': 'LR', 'clf': lr_score, 'p': ['l1','l2'], 'c': [0.1, 1.0, 10.0, 100.0], 'solver': ['liblinear'], 'seed': seed},\n",
    "    {'type': 'SVM', 'clf': linsvc_score, 'p': ['l2'], 'c': [0.1, 1.0, 10.0, 100.0], 'seed': seed},\n",
    "    {'type': 'Bagging_dtree', 'clf': bagging_score, 'n': [10, 50, 100], 'base':[None], 'seed':seed},\n",
    "    {'type': 'ADABoost_dtree', 'clf': adaboost_score, 'n': [10, 50, 100], 'base':[None], 'seed':seed},\n",
    "    {'type': 'Random Forest', 'clf': rforest_score, 'n': [10, 50, 100], 'criterion': ['entropy', 'gini'], 'seed': seed},\n",
    "    {'type': 'KNN', 'clf': knn_score, 'n': [5], 'weights': ['uniform','distance'], 'distance_metric':['minkowski'],'p': [1,2]}\n",
    "]\n",
    "\n",
    "#models = [{'type': 'Random Forest', 'clf': rforest_score, 'n': [10, 50, 100], 'criterion': ['entropy', 'gini'], 'seed': seed}]\n",
    "thresholds = [1, 2, 5, 10, 20,30, 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Dtree, run: 1\n",
      "criteria: entropy, depth: 10, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 500, seed: 12345\n",
      "model: LR, run: 1\n",
      "penalty: l1, c: 0.1, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 1.0, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 10.0, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 100.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 0.1, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 1.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 10.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 100.0, solver: liblinear, seed: 12345\n",
      "model: SVM, run: 1\n",
      "penalty: l2, c: 0.1, seed: 12345\n",
      "penalty: l2, c: 1.0, seed: 12345\n",
      "penalty: l2, c: 10.0, seed: 12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty: l2, c: 100.0, seed: 12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Bagging_dtree, run: 1\n",
      "model: ADABoost_dtree, run: 1\n",
      "model: Random Forest, run: 1\n",
      "model: KNN, run: 1\n",
      "n: 5, weights: uniform, distance: minkowski, p: 1\n",
      "n: 5, weights: uniform, distance: minkowski, p: 2\n",
      "n: 5, weights: distance, distance: minkowski, p: 1\n",
      "n: 5, weights: distance, distance: minkowski, p: 2\n",
      "model: Dtree, run: 2\n",
      "criteria: entropy, depth: 10, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 500, seed: 12345\n",
      "model: LR, run: 2\n",
      "penalty: l1, c: 0.1, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 1.0, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 10.0, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 100.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 0.1, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 1.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 10.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 100.0, solver: liblinear, seed: 12345\n",
      "model: SVM, run: 2\n",
      "penalty: l2, c: 0.1, seed: 12345\n",
      "penalty: l2, c: 1.0, seed: 12345\n",
      "penalty: l2, c: 10.0, seed: 12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty: l2, c: 100.0, seed: 12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Bagging_dtree, run: 2\n",
      "model: ADABoost_dtree, run: 2\n",
      "model: Random Forest, run: 2\n",
      "model: KNN, run: 2\n",
      "n: 5, weights: uniform, distance: minkowski, p: 1\n",
      "n: 5, weights: uniform, distance: minkowski, p: 2\n",
      "n: 5, weights: distance, distance: minkowski, p: 1\n",
      "n: 5, weights: distance, distance: minkowski, p: 2\n",
      "model: Dtree, run: 3\n",
      "criteria: entropy, depth: 10, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 10, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 20, min_leaf: 500, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 100, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 300, seed: 12345\n",
      "criteria: gini, depth: 30, min_leaf: 500, seed: 12345\n",
      "model: LR, run: 3\n",
      "penalty: l1, c: 0.1, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 1.0, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 10.0, solver: liblinear, seed: 12345\n",
      "penalty: l1, c: 100.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 0.1, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 1.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 10.0, solver: liblinear, seed: 12345\n",
      "penalty: l2, c: 100.0, solver: liblinear, seed: 12345\n",
      "model: SVM, run: 3\n",
      "penalty: l2, c: 0.1, seed: 12345\n",
      "penalty: l2, c: 1.0, seed: 12345\n",
      "penalty: l2, c: 10.0, seed: 12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty: l2, c: 100.0, seed: 12345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Bagging_dtree, run: 3\n",
      "model: ADABoost_dtree, run: 3\n",
      "model: Random Forest, run: 3\n",
      "model: KNN, run: 3\n",
      "n: 5, weights: uniform, distance: minkowski, p: 1\n",
      "n: 5, weights: uniform, distance: minkowski, p: 2\n",
      "n: 5, weights: distance, distance: minkowski, p: 1\n",
      "n: 5, weights: distance, distance: minkowski, p: 2\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(1, len(windows)-1):\n",
    "    train_start = windows[0]\n",
    "    train_end = windows[i]\n",
    "    test_end = windows[i+1]\n",
    "    \n",
    "    #split data\n",
    "    x_train,y_train,x_test,y_test = pp.single_train_test_set(df_final, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          train_start,\n",
    "                                                          train_end, \n",
    "                                                          test_end, \n",
    "                                                          pred_time=pred_time)\n",
    "    \n",
    "    \n",
    "    baseline = sum(y_test)/len(y_test)\n",
    "    #run models\n",
    "    for clf in models:\n",
    "        modeltype = clf['type']\n",
    "        func = clf['clf']\n",
    "        printinfo = 'model: {}, run: {}'.format(modeltype, i)\n",
    "        print(printinfo)\n",
    "        if modeltype == 'Dtree':\n",
    "            seed = clf['seed']\n",
    "            for c in clf['criteria']:\n",
    "                for d in clf['depth']:\n",
    "                    for l in clf['min_leaf']:\n",
    "                        #run model\n",
    "                        info = 'criteria: {}, depth: {}, min_leaf: {}, seed: {}'.format(c, d, l, seed)\n",
    "                        print(info)\n",
    "                        scores = func(x_train, y_train, x_test, criteria = c, depth = d, min_leaf = l, seed=seed)\n",
    "                        for pct_pop in thresholds:\n",
    "                            acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                            tmp = {'baseline': baseline, 'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                   'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                            \n",
    "        elif modeltype == 'LR':\n",
    "            seed = clf['seed']\n",
    "            for p in clf['p']:\n",
    "                for c in clf['c']:\n",
    "                    for s in clf['solver']:\n",
    "                        #print(p)\n",
    "                        info = 'penalty: {}, c: {}, solver: {}, seed: {}'.format(p, c, s, seed)\n",
    "                        print(info)\n",
    "                        scores = func(x_train, y_train, x_test, p = p, c = c, solver = s, seed=seed)\n",
    "                        for pct_pop in thresholds:\n",
    "                            acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                            tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                   'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                        \n",
    "        elif modeltype == 'SVM':\n",
    "            seed = clf['seed']\n",
    "            for p in clf['p']:\n",
    "                for c in clf['c']:\n",
    "                    info = 'penalty: {}, c: {}, seed: {}'.format(p, c, seed)\n",
    "                    print(info)\n",
    "                    scores = func(x_train, y_train, x_test, p =p, c=c, seed=seed)\n",
    "                    for pct_pop in thresholds:\n",
    "                        acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                        tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                               'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                        results.append(tmp)\n",
    "                            \n",
    "        elif modeltype == 'KNN':\n",
    "            for n in clf['n']:\n",
    "                for w in clf['weights']:\n",
    "                    for d in clf['distance_metric']:\n",
    "                        for p in clf['p']:\n",
    "                            info = 'n: {}, weights: {}, distance: {}, p: {}'.format(n, w, d, p)\n",
    "                            print(info)\n",
    "                            scores = func(x_train, y_train, x_test, n = n, weights = w, distance_metric = d, p=p)\n",
    "                            #print(list(scores))\n",
    "                            for pct_pop in thresholds:\n",
    "                                acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                                tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                       'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                                results.append(tmp)\n",
    "        \n",
    "        elif modeltype == 'Bagging_dtree':\n",
    "            seed = clf['seed']\n",
    "            for n in clf['n']:\n",
    "                for b in clf['base']:\n",
    "                    info = 'n: {}, base: {}'.format(n,b)\n",
    "                    scores = func(x_train, y_train, x_test, n = n, base = b, seed=seed)\n",
    "                    for pct_pop in thresholds:\n",
    "                        acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                        tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                               'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                        results.append(tmp)\n",
    "        \n",
    "        elif modeltype == 'ADABoost_dtree':\n",
    "            seed = clf['seed']\n",
    "            for n in clf['n']:\n",
    "                for b in clf['base']:\n",
    "                    info = 'n: {}, base: {}'.format(n,b)\n",
    "                    scores = func(x_train, y_train, x_test, n = n, base = b, seed=seed)\n",
    "                    for pct_pop in thresholds:\n",
    "                        acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                        tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                               'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                        results.append(tmp)\n",
    "            \n",
    "            \n",
    "        elif modeltype == 'Random Forest':\n",
    "            seed = clf['seed']\n",
    "            for n in clf['n']:\n",
    "                for c in clf['criterion']:\n",
    "                    info = 'n: {}, criterion: {}'.format(n,c)\n",
    "                    scores = func(x_train, y_train, x_test, n = n, criterion = c, seed=seed)\n",
    "                    for pct_pop in thresholds:\n",
    "                        acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                        tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                               'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                        results.append(tmp)\n",
    "                    \n",
    "                    \n",
    "resdf=pd.DataFrame(results, columns = ['type', 'details', 'baseline', 'threshold_pct', 'precision', 'recall', 'auc','train_set_num', 'train_start', 'test_start'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>details</th>\n",
       "      <th>baseline</th>\n",
       "      <th>threshold_pct</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>train_set_num</th>\n",
       "      <th>train_start</th>\n",
       "      <th>test_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930303</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>0.504909</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>2</td>\n",
       "      <td>0.825493</td>\n",
       "      <td>0.022211</td>\n",
       "      <td>0.504315</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>5</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.051609</td>\n",
       "      <td>0.503131</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>10</td>\n",
       "      <td>0.753034</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>0.502606</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>20</td>\n",
       "      <td>0.748786</td>\n",
       "      <td>0.201535</td>\n",
       "      <td>0.502988</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>30</td>\n",
       "      <td>0.745449</td>\n",
       "      <td>0.300955</td>\n",
       "      <td>0.501859</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>50</td>\n",
       "      <td>0.741808</td>\n",
       "      <td>0.499143</td>\n",
       "      <td>0.498331</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>0.504830</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>2</td>\n",
       "      <td>0.825493</td>\n",
       "      <td>0.022211</td>\n",
       "      <td>0.504315</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>5</td>\n",
       "      <td>0.765170</td>\n",
       "      <td>0.051486</td>\n",
       "      <td>0.502892</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>10</td>\n",
       "      <td>0.753337</td>\n",
       "      <td>0.101380</td>\n",
       "      <td>0.502686</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>20</td>\n",
       "      <td>0.748635</td>\n",
       "      <td>0.201494</td>\n",
       "      <td>0.502908</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>30</td>\n",
       "      <td>0.745449</td>\n",
       "      <td>0.300955</td>\n",
       "      <td>0.501859</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>50</td>\n",
       "      <td>0.741808</td>\n",
       "      <td>0.499143</td>\n",
       "      <td>0.498331</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>0.012616</td>\n",
       "      <td>0.505068</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>2</td>\n",
       "      <td>0.831563</td>\n",
       "      <td>0.022375</td>\n",
       "      <td>0.504633</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>5</td>\n",
       "      <td>0.766383</td>\n",
       "      <td>0.051568</td>\n",
       "      <td>0.503051</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>10</td>\n",
       "      <td>0.754854</td>\n",
       "      <td>0.101584</td>\n",
       "      <td>0.503083</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>20</td>\n",
       "      <td>0.748786</td>\n",
       "      <td>0.201535</td>\n",
       "      <td>0.502988</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>30</td>\n",
       "      <td>0.745348</td>\n",
       "      <td>0.300915</td>\n",
       "      <td>0.501780</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>50</td>\n",
       "      <td>0.741869</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.498411</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875758</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.503479</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>2</td>\n",
       "      <td>0.798179</td>\n",
       "      <td>0.021476</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>5</td>\n",
       "      <td>0.755461</td>\n",
       "      <td>0.050833</td>\n",
       "      <td>0.501621</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>10</td>\n",
       "      <td>0.749090</td>\n",
       "      <td>0.100808</td>\n",
       "      <td>0.501573</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>20</td>\n",
       "      <td>0.746966</td>\n",
       "      <td>0.201045</td>\n",
       "      <td>0.502034</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>30</td>\n",
       "      <td>0.744640</td>\n",
       "      <td>0.300629</td>\n",
       "      <td>0.501224</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>50</td>\n",
       "      <td>0.741019</td>\n",
       "      <td>0.498612</td>\n",
       "      <td>0.497298</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.684111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940092</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>0.505921</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.684111</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801843</td>\n",
       "      <td>0.023434</td>\n",
       "      <td>0.505446</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.684111</td>\n",
       "      <td>30</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.296835</td>\n",
       "      <td>0.494998</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.684111</td>\n",
       "      <td>50</td>\n",
       "      <td>0.680118</td>\n",
       "      <td>0.497104</td>\n",
       "      <td>0.495380</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.505883</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830125</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.505634</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>5</td>\n",
       "      <td>0.770380</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>10</td>\n",
       "      <td>0.740095</td>\n",
       "      <td>0.103466</td>\n",
       "      <td>0.506076</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>20</td>\n",
       "      <td>0.726820</td>\n",
       "      <td>0.203197</td>\n",
       "      <td>0.505631</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>30</td>\n",
       "      <td>0.720528</td>\n",
       "      <td>0.302168</td>\n",
       "      <td>0.503812</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 0.1, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>50</td>\n",
       "      <td>0.719933</td>\n",
       "      <td>0.503213</td>\n",
       "      <td>0.505623</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.505883</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.831257</td>\n",
       "      <td>0.023232</td>\n",
       "      <td>0.505690</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>5</td>\n",
       "      <td>0.770380</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>10</td>\n",
       "      <td>0.740321</td>\n",
       "      <td>0.103497</td>\n",
       "      <td>0.506131</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>20</td>\n",
       "      <td>0.726933</td>\n",
       "      <td>0.203228</td>\n",
       "      <td>0.505687</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>30</td>\n",
       "      <td>0.720604</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.503868</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 1.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>50</td>\n",
       "      <td>0.719888</td>\n",
       "      <td>0.503181</td>\n",
       "      <td>0.505568</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957014</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.505938</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830125</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.505634</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>5</td>\n",
       "      <td>0.770380</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>10</td>\n",
       "      <td>0.740774</td>\n",
       "      <td>0.103561</td>\n",
       "      <td>0.506243</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>20</td>\n",
       "      <td>0.726707</td>\n",
       "      <td>0.203165</td>\n",
       "      <td>0.505576</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>30</td>\n",
       "      <td>0.720604</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.503868</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 10.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>50</td>\n",
       "      <td>0.719933</td>\n",
       "      <td>0.503213</td>\n",
       "      <td>0.505623</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900452</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>0.504549</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>2</td>\n",
       "      <td>0.798414</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>0.504078</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>5</td>\n",
       "      <td>0.758605</td>\n",
       "      <td>0.053015</td>\n",
       "      <td>0.505309</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>10</td>\n",
       "      <td>0.734888</td>\n",
       "      <td>0.102738</td>\n",
       "      <td>0.504797</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>20</td>\n",
       "      <td>0.724556</td>\n",
       "      <td>0.202564</td>\n",
       "      <td>0.504519</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>30</td>\n",
       "      <td>0.719245</td>\n",
       "      <td>0.301630</td>\n",
       "      <td>0.502867</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>SVM</td>\n",
       "      <td>penalty: l2, c: 100.0, seed: 12345</td>\n",
       "      <td>0.715353</td>\n",
       "      <td>50</td>\n",
       "      <td>0.719073</td>\n",
       "      <td>0.502611</td>\n",
       "      <td>0.504567</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                             details  baseline  threshold_pct  \\\n",
       "182  SVM    penalty: l2, c: 0.1, seed: 12345  0.743083              1   \n",
       "183  SVM    penalty: l2, c: 0.1, seed: 12345  0.743083              2   \n",
       "184  SVM    penalty: l2, c: 0.1, seed: 12345  0.743083              5   \n",
       "185  SVM    penalty: l2, c: 0.1, seed: 12345  0.743083             10   \n",
       "186  SVM    penalty: l2, c: 0.1, seed: 12345  0.743083             20   \n",
       "187  SVM    penalty: l2, c: 0.1, seed: 12345  0.743083             30   \n",
       "188  SVM    penalty: l2, c: 0.1, seed: 12345  0.743083             50   \n",
       "189  SVM    penalty: l2, c: 1.0, seed: 12345  0.743083              1   \n",
       "190  SVM    penalty: l2, c: 1.0, seed: 12345  0.743083              2   \n",
       "191  SVM    penalty: l2, c: 1.0, seed: 12345  0.743083              5   \n",
       "192  SVM    penalty: l2, c: 1.0, seed: 12345  0.743083             10   \n",
       "193  SVM    penalty: l2, c: 1.0, seed: 12345  0.743083             20   \n",
       "194  SVM    penalty: l2, c: 1.0, seed: 12345  0.743083             30   \n",
       "195  SVM    penalty: l2, c: 1.0, seed: 12345  0.743083             50   \n",
       "196  SVM   penalty: l2, c: 10.0, seed: 12345  0.743083              1   \n",
       "197  SVM   penalty: l2, c: 10.0, seed: 12345  0.743083              2   \n",
       "198  SVM   penalty: l2, c: 10.0, seed: 12345  0.743083              5   \n",
       "199  SVM   penalty: l2, c: 10.0, seed: 12345  0.743083             10   \n",
       "200  SVM   penalty: l2, c: 10.0, seed: 12345  0.743083             20   \n",
       "201  SVM   penalty: l2, c: 10.0, seed: 12345  0.743083             30   \n",
       "202  SVM   penalty: l2, c: 10.0, seed: 12345  0.743083             50   \n",
       "203  SVM  penalty: l2, c: 100.0, seed: 12345  0.743083              1   \n",
       "204  SVM  penalty: l2, c: 100.0, seed: 12345  0.743083              2   \n",
       "205  SVM  penalty: l2, c: 100.0, seed: 12345  0.743083              5   \n",
       "206  SVM  penalty: l2, c: 100.0, seed: 12345  0.743083             10   \n",
       "207  SVM  penalty: l2, c: 100.0, seed: 12345  0.743083             20   \n",
       "208  SVM  penalty: l2, c: 100.0, seed: 12345  0.743083             30   \n",
       "209  SVM  penalty: l2, c: 100.0, seed: 12345  0.743083             50   \n",
       "504  SVM    penalty: l2, c: 0.1, seed: 12345  0.684111              1   \n",
       "505  SVM    penalty: l2, c: 0.1, seed: 12345  0.684111              2   \n",
       "..   ...                                 ...       ...            ...   \n",
       "530  SVM  penalty: l2, c: 100.0, seed: 12345  0.684111             30   \n",
       "531  SVM  penalty: l2, c: 100.0, seed: 12345  0.684111             50   \n",
       "826  SVM    penalty: l2, c: 0.1, seed: 12345  0.715353              1   \n",
       "827  SVM    penalty: l2, c: 0.1, seed: 12345  0.715353              2   \n",
       "828  SVM    penalty: l2, c: 0.1, seed: 12345  0.715353              5   \n",
       "829  SVM    penalty: l2, c: 0.1, seed: 12345  0.715353             10   \n",
       "830  SVM    penalty: l2, c: 0.1, seed: 12345  0.715353             20   \n",
       "831  SVM    penalty: l2, c: 0.1, seed: 12345  0.715353             30   \n",
       "832  SVM    penalty: l2, c: 0.1, seed: 12345  0.715353             50   \n",
       "833  SVM    penalty: l2, c: 1.0, seed: 12345  0.715353              1   \n",
       "834  SVM    penalty: l2, c: 1.0, seed: 12345  0.715353              2   \n",
       "835  SVM    penalty: l2, c: 1.0, seed: 12345  0.715353              5   \n",
       "836  SVM    penalty: l2, c: 1.0, seed: 12345  0.715353             10   \n",
       "837  SVM    penalty: l2, c: 1.0, seed: 12345  0.715353             20   \n",
       "838  SVM    penalty: l2, c: 1.0, seed: 12345  0.715353             30   \n",
       "839  SVM    penalty: l2, c: 1.0, seed: 12345  0.715353             50   \n",
       "840  SVM   penalty: l2, c: 10.0, seed: 12345  0.715353              1   \n",
       "841  SVM   penalty: l2, c: 10.0, seed: 12345  0.715353              2   \n",
       "842  SVM   penalty: l2, c: 10.0, seed: 12345  0.715353              5   \n",
       "843  SVM   penalty: l2, c: 10.0, seed: 12345  0.715353             10   \n",
       "844  SVM   penalty: l2, c: 10.0, seed: 12345  0.715353             20   \n",
       "845  SVM   penalty: l2, c: 10.0, seed: 12345  0.715353             30   \n",
       "846  SVM   penalty: l2, c: 10.0, seed: 12345  0.715353             50   \n",
       "847  SVM  penalty: l2, c: 100.0, seed: 12345  0.715353              1   \n",
       "848  SVM  penalty: l2, c: 100.0, seed: 12345  0.715353              2   \n",
       "849  SVM  penalty: l2, c: 100.0, seed: 12345  0.715353              5   \n",
       "850  SVM  penalty: l2, c: 100.0, seed: 12345  0.715353             10   \n",
       "851  SVM  penalty: l2, c: 100.0, seed: 12345  0.715353             20   \n",
       "852  SVM  penalty: l2, c: 100.0, seed: 12345  0.715353             30   \n",
       "853  SVM  penalty: l2, c: 100.0, seed: 12345  0.715353             50   \n",
       "\n",
       "     precision    recall       auc  train_set_num train_start test_start  \n",
       "182   0.930303  0.012535  0.504909              1  2012-01-01 2012-07-01  \n",
       "183   0.825493  0.022211  0.504315              1  2012-01-01 2012-07-01  \n",
       "184   0.766990  0.051609  0.503131              1  2012-01-01 2012-07-01  \n",
       "185   0.753034  0.101339  0.502606              1  2012-01-01 2012-07-01  \n",
       "186   0.748786  0.201535  0.502988              1  2012-01-01 2012-07-01  \n",
       "187   0.745449  0.300955  0.501859              1  2012-01-01 2012-07-01  \n",
       "188   0.741808  0.499143  0.498331              1  2012-01-01 2012-07-01  \n",
       "189   0.927273  0.012494  0.504830              1  2012-01-01 2012-07-01  \n",
       "190   0.825493  0.022211  0.504315              1  2012-01-01 2012-07-01  \n",
       "191   0.765170  0.051486  0.502892              1  2012-01-01 2012-07-01  \n",
       "192   0.753337  0.101380  0.502686              1  2012-01-01 2012-07-01  \n",
       "193   0.748635  0.201494  0.502908              1  2012-01-01 2012-07-01  \n",
       "194   0.745449  0.300955  0.501859              1  2012-01-01 2012-07-01  \n",
       "195   0.741808  0.499143  0.498331              1  2012-01-01 2012-07-01  \n",
       "196   0.936364  0.012616  0.505068              1  2012-01-01 2012-07-01  \n",
       "197   0.831563  0.022375  0.504633              1  2012-01-01 2012-07-01  \n",
       "198   0.766383  0.051568  0.503051              1  2012-01-01 2012-07-01  \n",
       "199   0.754854  0.101584  0.503083              1  2012-01-01 2012-07-01  \n",
       "200   0.748786  0.201535  0.502988              1  2012-01-01 2012-07-01  \n",
       "201   0.745348  0.300915  0.501780              1  2012-01-01 2012-07-01  \n",
       "202   0.741869  0.499183  0.498411              1  2012-01-01 2012-07-01  \n",
       "203   0.875758  0.011800  0.503479              1  2012-01-01 2012-07-01  \n",
       "204   0.798179  0.021476  0.502885              1  2012-01-01 2012-07-01  \n",
       "205   0.755461  0.050833  0.501621              1  2012-01-01 2012-07-01  \n",
       "206   0.749090  0.100808  0.501573              1  2012-01-01 2012-07-01  \n",
       "207   0.746966  0.201045  0.502034              1  2012-01-01 2012-07-01  \n",
       "208   0.744640  0.300629  0.501224              1  2012-01-01 2012-07-01  \n",
       "209   0.741019  0.498612  0.497298              1  2012-01-01 2012-07-01  \n",
       "504   0.940092  0.013737  0.505921              2  2012-01-01 2013-01-01  \n",
       "505   0.801843  0.023434  0.505446              2  2012-01-01 2013-01-01  \n",
       "..         ...       ...       ...            ...         ...        ...  \n",
       "530   0.676904  0.296835  0.494998              2  2012-01-01 2013-01-01  \n",
       "531   0.680118  0.497104  0.495380              2  2012-01-01 2013-01-01  \n",
       "826   0.954751  0.013357  0.505883              3  2012-01-01 2013-07-01  \n",
       "827   0.830125  0.023200  0.505634              3  2012-01-01 2013-07-01  \n",
       "828   0.770380  0.053838  0.506755              3  2012-01-01 2013-07-01  \n",
       "829   0.740095  0.103466  0.506076              3  2012-01-01 2013-07-01  \n",
       "830   0.726820  0.203197  0.505631              3  2012-01-01 2013-07-01  \n",
       "831   0.720528  0.302168  0.503812              3  2012-01-01 2013-07-01  \n",
       "832   0.719933  0.503213  0.505623              3  2012-01-01 2013-07-01  \n",
       "833   0.954751  0.013357  0.505883              3  2012-01-01 2013-07-01  \n",
       "834   0.831257  0.023232  0.505690              3  2012-01-01 2013-07-01  \n",
       "835   0.770380  0.053838  0.506755              3  2012-01-01 2013-07-01  \n",
       "836   0.740321  0.103497  0.506131              3  2012-01-01 2013-07-01  \n",
       "837   0.726933  0.203228  0.505687              3  2012-01-01 2013-07-01  \n",
       "838   0.720604  0.302200  0.503868              3  2012-01-01 2013-07-01  \n",
       "839   0.719888  0.503181  0.505568              3  2012-01-01 2013-07-01  \n",
       "840   0.957014  0.013388  0.505938              3  2012-01-01 2013-07-01  \n",
       "841   0.830125  0.023200  0.505634              3  2012-01-01 2013-07-01  \n",
       "842   0.770380  0.053838  0.506755              3  2012-01-01 2013-07-01  \n",
       "843   0.740774  0.103561  0.506243              3  2012-01-01 2013-07-01  \n",
       "844   0.726707  0.203165  0.505576              3  2012-01-01 2013-07-01  \n",
       "845   0.720604  0.302200  0.503868              3  2012-01-01 2013-07-01  \n",
       "846   0.719933  0.503213  0.505623              3  2012-01-01 2013-07-01  \n",
       "847   0.900452  0.012597  0.504549              3  2012-01-01 2013-07-01  \n",
       "848   0.798414  0.022314  0.504078              3  2012-01-01 2013-07-01  \n",
       "849   0.758605  0.053015  0.505309              3  2012-01-01 2013-07-01  \n",
       "850   0.734888  0.102738  0.504797              3  2012-01-01 2013-07-01  \n",
       "851   0.724556  0.202564  0.504519              3  2012-01-01 2013-07-01  \n",
       "852   0.719245  0.301630  0.502867              3  2012-01-01 2013-07-01  \n",
       "853   0.719073  0.502611  0.504567              3  2012-01-01 2013-07-01  \n",
       "\n",
       "[84 rows x 10 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf[resdf['type'] == 'SVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resdf.to_csv('finalrun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use temporal validation to split into training/test sets\n",
    "\n",
    "\n",
    "\n",
    "x_train1,y_train1,x_test1,y_test1 = pp.single_train_test_set(df_final, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          windows[0],\n",
    "                                                          windows[1], \n",
    "                                                          windows[2], \n",
    "                                                          pred_time=60)\n",
    "\n",
    "x_train2, y_train2, x_test2, y_test2 = pp.single_train_test_set(df_final, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          windows[0],\n",
    "                                                          windows[2], \n",
    "                                                          windows[3], \n",
    "                                                          pred_time=60)\n",
    "\n",
    "x_train3, y_train3, x_test3, y_test3 = pp.single_train_test_set(df_final, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          windows[0],\n",
    "                                                          windows[3], \n",
    "                                                          windows[4], \n",
    "                                                          pred_time=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59249728, 0.23252579, 0.09679977, ..., 0.62204465, 0.62930204,\n",
       "       0.34233743])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = linsvc_score(x_train1, y_train1, x_test1, p='l2', c=0.1, seed=12345)\n",
    "#all_metrics(y_test1, test, 1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(test)*0.01,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  290, 28297, 14704, 14551,  2849,  5898,  2946, 11235, 16977,\n",
       "            12828,\n",
       "            ...\n",
       "            25522, 12997, 21633, 25774, 28395, 28144,  8868, 16439, 28460,\n",
       "            21175],\n",
       "           dtype='int64', length=330)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.Series(test)\n",
    "idxtestdf = testdf.sort_values(ascending=False)[0:330].index\n",
    "idxtestdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_pctpop(test,1).iloc[290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26407766990291265"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_at_threshold(y_test1, testdf, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010012135922330098"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.iloc[:] = 0\n",
    "testdf.iloc[idxtestdf] = 1\n",
    "sum(testdf)/len(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = [1 if x > 1.0 else 0 for x in test]\n",
    "metrics.precision_score(y_test1, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = knn_score(x_train1, y_train1, x_test1, n=3, p=1)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_at_threshold(y_test1, clf, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test1, x)\n",
    "p = precision[0:-1]\n",
    "r = recall[0:-1]\n",
    "t = 1-thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.percentile(x,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test = lr_score(x_train1, y_train1, x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1 if x > t else 0 for x in lr_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test)/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.percentile(lr_test, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_score(x_train1, y_train1, x_test1, 15, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def adaboost_score(x_train, y_train, x_test, n, base = None, seed=12345):\n",
    "    '''\n",
    "    This function creates and predicts scores using bagging.\n",
    "    \n",
    "    x_train: training set features\n",
    "    y_train: training set labels\n",
    "    x_test: test set features\n",
    "    n_estimators: number of estimators to be in bagging\n",
    "    base: base classifier, default None is Dtree\n",
    "    n_jobs = jobs to do in parallel\n",
    "    \n",
    "    returns: predicted scores \n",
    "    '''\n",
    "    \n",
    "    ada = AdaBoostClassifier(base_estimator = base, n_estimators=n, random_state=seed)\n",
    "    ada.fit(x_train, y_train)\n",
    "    return predictpr(ada,x_test)\n",
    "\n",
    "def bagging_score(x_train, y_train, x_test, n, base = None, n_jobs = 1, seed= 12345):\n",
    "    '''\n",
    "    This function creates and predicts scores using bagging.\n",
    "    \n",
    "    x_train: training set features\n",
    "    y_train: training set labels\n",
    "    x_test: test set features\n",
    "    n_estimators: number of estimators to be in bagging\n",
    "    base: base classifier, default None is Dtree\n",
    "    n_jobs = jobs to do in parallel\n",
    "    \n",
    "    returns: predicted scores \n",
    "    '''\n",
    "    \n",
    "    bag = BaggingClassifier(base_estimator=base, n_estimators= n, n_jobs = n_jobs, random_state = seed)\n",
    "    bag.fit(x_train, y_train)\n",
    "    return predictpr(bag, x_test)\n",
    "\n",
    "def rforest_score(x_train, y_train, x_test, n, criterion = 'entropy', max_depth = None, n_jobs= None, seed=seed):\n",
    "    '''\n",
    "    This function returns probabilities from a Random Forest Classifier\n",
    "    \n",
    "    x_train: training set features\n",
    "    y_train: training set labels\n",
    "    x_test: test set features\n",
    "    n: n_estimators\n",
    "    criterion: entropy or gig\n",
    "    max_depth: depth of tree, None default means nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "    n_jobs: number of jobs to run in parallel for both fit and predict. None means 1\n",
    "    seed: random seed\n",
    "    \n",
    "    return: prediction scores\n",
    "    '''\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=n, criterion= criterion, max_depth=max_depth, n_jobs=n_jobs, random_state=seed)\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    return predictpr(rf, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_pctpop(pred_scores, pct_pop):\n",
    "    \n",
    "    #identify number of positives to have given target percent of population\n",
    "    num_pos = int(round(len(pred_scores)*(pct_pop/100),0))\n",
    "    #turn predictions into series\n",
    "    pred_df = pd.Series(pred_scores)\n",
    "    idx = pred_df.sort_values(ascending=False)[0:num_pos].index \n",
    "    \n",
    "    #set all observations to 0\n",
    "    pred_df.iloc[:] = 0\n",
    "    #set observations by index (the ones ranked high enough) to 1\n",
    "    pred_df.iloc[idx] = 1\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "def all_metrics(y_test, pred_scores, t, target_pop = True):\n",
    "    '''\n",
    "    This function returns the accuracy, precision, recall, f1, and auc_roc for a given target percent of population\n",
    "    \n",
    "    y_test: tests set labels\n",
    "    pred_scores: prediction scores\n",
    "    t: threshold (either decimal as threshold or integer as % target population (50 is 50%))\n",
    "    target_pop: boolean to decide whether to use t as threshold or target pop\n",
    "    \n",
    "    return: tuple with accuracy, precision, recall, f1, and auc_roc\n",
    "    '''\n",
    "    if target_pop:\n",
    "        pred_scores = scores_pctpop(pred_scores, t)\n",
    "        t = 0.5\n",
    "\n",
    "    acc = accuracy_at_threshold(y_test, pred_scores, t)\n",
    "    prec = precision_at_threshold(y_test, pred_scores, t)\n",
    "    rec = recall_at_threshold(y_test, pred_scores, t)\n",
    "    f1 = f1_at_threshold(y_test, pred_scores, t)\n",
    "    auc = auc_roc(y_test, pred_scores)\n",
    "    \n",
    "    return (acc, prec, rec, f1, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(models, thresholds, windows, df_final, feature_cols, label_col, split_col, pred_time, pred_unit = 'day', filename = ''):\n",
    "    '''\n",
    "    This function runs multiple models with multiple parameters and calculates metrics according to thresholds\n",
    "\n",
    "    models: list of dictionaries, each one is a model type with parameters\n",
    "    thresholds: list of thresholds to calculate metrics against for each model\n",
    "    windows: list of start and end dates for time windows\n",
    "    feature_cols: list of strings, column names\n",
    "    label_col: column name of label\n",
    "    split_col: column name of column that has the dates to split on\n",
    "    pred_time: prediction window\n",
    "    pred_unit: time unit for prediction window\n",
    "    filename: csv filename to save results\n",
    "\n",
    "    returns: dataframe\n",
    "    '''\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(1, len(windows)-1):\n",
    "        train_start = windows[0]\n",
    "        train_end = windows[i]\n",
    "        test_end = windows[i+1]\n",
    "        \n",
    "        #split data\n",
    "        x_train,y_train,x_test,y_test = pp.single_train_test_set(df_final, \n",
    "                                                            feature_cols, \n",
    "                                                            label_col, \n",
    "                                                            split_col, \n",
    "                                                            train_start,\n",
    "                                                            train_end, \n",
    "                                                            test_end, \n",
    "                                                            pred_time=pred_time, pred_unit = pred_unit)\n",
    "        \n",
    "        \n",
    "        baseline = sum(y_test)/len(y_test)\n",
    "        #run models\n",
    "        for clf in models:\n",
    "            modeltype = clf['type']\n",
    "            func = clf['clf']\n",
    "            printinfo = 'model: {}, run: {}'.format(modeltype, i)\n",
    "            print(printinfo)\n",
    "            if modeltype == 'Dtree':\n",
    "                seed = clf['seed']\n",
    "                for c in clf['criteria']:\n",
    "                    for d in clf['depth']:\n",
    "                        for l in clf['min_leaf']:\n",
    "                            #run model\n",
    "                            info = 'criteria: {}, depth: {}, min_leaf: {}, seed: {}'.format(c, d, l, seed)\n",
    "                            print(info)\n",
    "                            scores = func(x_train, y_train, x_test, criteria = c, depth = d, min_leaf = l, seed=seed)\n",
    "                            for pct_pop in thresholds:\n",
    "                                acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                                tmp = {'baseline': baseline, 'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                    'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                                results.append(tmp)\n",
    "                                \n",
    "            elif modeltype == 'LR':\n",
    "                seed = clf['seed']\n",
    "                for p in clf['p']:\n",
    "                    for c in clf['c']:\n",
    "                        for s in clf['solver']:\n",
    "                            #print(p)\n",
    "                            info = 'penalty: {}, c: {}, solver: {}, seed: {}'.format(p, c, s, seed)\n",
    "                            print(info)\n",
    "                            scores = func(x_train, y_train, x_test, p = p, c = c, solver = s, seed=seed)\n",
    "                            for pct_pop in thresholds:\n",
    "                                acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                                tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                    'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                                results.append(tmp)\n",
    "                            \n",
    "            elif modeltype == 'SVM':\n",
    "                seed = clf['seed']\n",
    "                for p in clf['p']:\n",
    "                    for c in clf['c']:\n",
    "                        info = 'penalty: {}, c: {}, seed: {}'.format(p, c, seed)\n",
    "                        print(info)\n",
    "                        scores = func(x_train, y_train, x_test, p =p, c=c, seed=seed)\n",
    "                        for pct_pop in thresholds:\n",
    "                            acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                            tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                                \n",
    "            elif modeltype == 'KNN':\n",
    "                for n in clf['n']:\n",
    "                    for w in clf['weights']:\n",
    "                        for d in clf['distance_metric']:\n",
    "                            for p in clf['p']:\n",
    "                                info = 'n: {}, weights: {}, distance: {}, p: {}'.format(n, w, d, p)\n",
    "                                print(info)\n",
    "                                scores = func(x_train, y_train, x_test, n = n, weights = w, distance_metric = d, p=p)\n",
    "                                #print(list(scores))\n",
    "                                for pct_pop in thresholds:\n",
    "                                    acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                                    tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                        'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                                    results.append(tmp)\n",
    "            \n",
    "            elif modeltype == 'Bagging_dtree':\n",
    "                seed = clf['seed']\n",
    "                for n in clf['n']:\n",
    "                    for b in clf['base']:\n",
    "                        info = 'n: {}, base: {}'.format(n,b)\n",
    "                        scores = func(x_train, y_train, x_test, n = n, base = b, seed=seed)\n",
    "                        for pct_pop in thresholds:\n",
    "                            acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                            tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "            \n",
    "            elif modeltype == 'ADABoost_dtree':\n",
    "                seed = clf['seed']\n",
    "                for n in clf['n']:\n",
    "                    for b in clf['base']:\n",
    "                        info = 'n: {}, base: {}'.format(n,b)\n",
    "                        scores = func(x_train, y_train, x_test, n = n, base = b, seed=seed)\n",
    "                        for pct_pop in thresholds:\n",
    "                            acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                            tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                \n",
    "                \n",
    "            elif modeltype == 'Random Forest':\n",
    "                seed = clf['seed']\n",
    "                for n in clf['n']:\n",
    "                    for c in clf['criterion']:\n",
    "                        info = 'n: {}, criterion: {}'.format(n,c)\n",
    "                        scores = func(x_train, y_train, x_test, n = n, criterion = c, seed=seed)\n",
    "                        for pct_pop in thresholds:\n",
    "                            acc, prec, rec, f1, auc = all_metrics(y_test, scores, pct_pop)\n",
    "                            tmp = {'baseline': baseline,'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                                      \n",
    "    resdf = pd.DataFrame(results, columns = ['type', 'details', 'baseline', 'threshold_pct', 'precision', 'recall', 'auc','train_set_num', 'train_start', 'test_start'])    \n",
    "    if filename:\n",
    "        resdf.to_csv(filename)\n",
    "    return resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Dtree, run: 1\n",
      "criteria: entropy, depth: 10, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 10, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 300, seed: 12345\n",
      "criteria: entropy, depth: 20, min_leaf: 500, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 100, seed: 12345\n",
      "criteria: entropy, depth: 30, min_leaf: 300, seed: 12345\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-48bf7582977e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_unit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-02e16d0c37a4>\u001b[0m in \u001b[0;36mrun_models\u001b[0;34m(models, thresholds, windows, df_final, feature_cols, label_col, split_col, pred_time, pred_unit, filename)\u001b[0m\n\u001b[1;32m     51\u001b[0m                             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mpct_pop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                                 \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_pop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                                 tmp = {'baseline': baseline, 'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n\u001b[1;32m     55\u001b[0m                                     'details': info, 'threshold_pct': pct_pop, 'precision': prec, 'recall': rec, 'auc': auc}\n",
      "\u001b[0;32m<ipython-input-105-039cdbd3300c>\u001b[0m in \u001b[0;36mall_metrics\u001b[0;34m(y_test, pred_scores, t, target_pop)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_at_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_at_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_at_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-82e4e5085f7f>\u001b[0m in \u001b[0;36mf1_at_threshold\u001b[0;34m(y_test, pred_scores, thresh)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mpred_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mauc_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m_unique_multiclass\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_unique_multiclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x=run_models(models, thresholds, windows, df_final, feature_cols, label_col, split_col, pred_time, pred_unit = 'day', filename = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

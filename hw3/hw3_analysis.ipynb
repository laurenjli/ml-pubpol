{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def predictpr(fitted, feature_test):\n",
    "    '''\n",
    "    This function predicts the probability of response 1 for the test dataset.\n",
    "    \n",
    "    fitted: fitted classifier\n",
    "    feature_test: feature set in test data\n",
    "    \n",
    "    return: predictions\n",
    "    '''\n",
    "    return fitted.predict_proba(feature_test)[:,1]\n",
    "\n",
    "def knn_score(x_train, y_train, x_test, n, weights = 'uniform', distance_metric = 'minkowski', p=2):\n",
    "    '''\n",
    "    This function builds a KNN classifier.\n",
    "    \n",
    "    x_train: training set with features\n",
    "    y_train: training set with labels\n",
    "    n: number of neighbors\n",
    "    weights: weight function used in prediction.\n",
    "    distance_metric: the distance metric to use\n",
    "    p: Power parameter for the Minkowski metric. \n",
    "    \n",
    "    returns: fitted KNN classifier\n",
    "    '''\n",
    "    if distance_metric == 'minkowski':\n",
    "        knn = KNeighborsClassifier(n_neighbors=10, weights = weights, p=p, metric= distance_metric)\n",
    "        \n",
    "    else:\n",
    "        knn =KNeighborsClassifier(n_neighbors=10, weights = weights, metric= distance_metric)\n",
    "    \n",
    "    fitted = knn.fit(x_train, y_train)\n",
    "    \n",
    "    return predictpr(fitted, x_test)\n",
    "\n",
    "#can use existing prediction function to predict scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def lr_score(x_train, y_train, x_test, p = 'l1', c = 1.0, solver = 'liblinear', seed=12345):\n",
    "    '''\n",
    "    This function builds a Logistic Regression model.\n",
    "    \n",
    "    x_train: training set with features\n",
    "    y_train: training set with labels\n",
    "    p: penalty (l1 or l2)\n",
    "    c: Inverse of regularization strength; must be a positive float.\n",
    "    solver: Algorithm to use in the optimization problem.\n",
    "    seed: random seed\n",
    "    \n",
    "    returns fitted Logistic Regression\n",
    "    '''\n",
    "    \n",
    "    lr = LogisticRegression(penalty = p, C = c, solver= solver, random_state = seed)\n",
    "    fitted = lr.fit(x_train, y_train)\n",
    "    \n",
    "    return predictpr(fitted, x_test)\n",
    "\n",
    "\n",
    "#can use existing prediction function to predict scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def linsvc_score(x_train, y_train, x_test, p = 'l2', c = 1.0, seed = 12345):\n",
    "    '''\n",
    "    This function builds a fitted linear SVC\n",
    "    \n",
    "    x_train: training set with features\n",
    "    y_train: training set with labels\n",
    "    p: penalty (l2)\n",
    "    c: Penalty parameter C of the error term\n",
    "    seed: random seed\n",
    "    \n",
    "    returns fitted linear SVC\n",
    "    '''\n",
    "    \n",
    "    lsvc = LinearSVC(penalty = 'l2', C=c, seed=seed)\n",
    "    lsvc.fit(x_train, y_train)\n",
    "    \n",
    "    return lsvc.decision_function(x_test)\n",
    "\n",
    "def svm_score(fitted_lsvc, x_test):\n",
    "    '''\n",
    "    This function uses a test set to make scores using Linear SVC.\n",
    "    \n",
    "    fitted_lsvc: fitted Linear SVC\n",
    "    x_test: test set with features\n",
    "    \n",
    "    returns predictions\n",
    "    '''\n",
    "    return fitted_lsvc.decision_function(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "def build_cmatrix(y_test, pred_scores, threshold):\n",
    "    '''\n",
    "    This function builds a confusion matrix for a given threshold\n",
    "    \n",
    "    pred_scores: prediction scores\n",
    "    y_test: real labels\n",
    "    threshold: threshold for predictions\n",
    "    \n",
    "    returns tuple (true_negatives, false_positive, false_negatives, true_positives)\n",
    "    '''\n",
    "    pred = [1 if x > threshold else 0 for x in pred_scores]\n",
    "    \n",
    "    cmatrix = confusion_matrix(y_test, pred)\n",
    "    \n",
    "    true_negatives, false_positive, false_negatives, true_positives = cmatrix.ravel()\n",
    "\n",
    "    return (true_negatives, false_positive, false_negatives, true_positives)\n",
    "\n",
    "def precision_at_threshold(y_test, pred_scores, thresh =0.5):\n",
    "    '''\n",
    "    This function calculates precision of model given a threshold\n",
    "\n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    threshold: threshold for predictions\n",
    "\n",
    "    returns precision\n",
    "    '''\n",
    "    pred_one = [1 if x > threshold else 0 for x in pred_scores]\n",
    "    \n",
    "    return metrics.precision_score(y_test, pred_one)\n",
    "\n",
    "def recall_at_threshold(y_test, pred_scores, thresh =0.5):\n",
    "    '''\n",
    "    This function calculates recall of model given a threshold\n",
    "\n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    threshold: threshold for predictions\n",
    "\n",
    "    returns recall\n",
    "    '''\n",
    "    pred_one = [1 if x > threshold else 0 for x in pred_scores]\n",
    "    \n",
    "    return metrics.recall_score(y_test, pred_one)\n",
    "\n",
    "def f1_at_threshold(y_test, pred_scores, thresh =0.5):\n",
    "    '''\n",
    "    This function calculates that accuracy of model given a threshold\n",
    "\n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    threshold: threshold for predictions\n",
    "\n",
    "    returns f1 score \n",
    "    '''\n",
    "    pred_one = [1 if x > threshold else 0 for x in pred_scores]\n",
    "    \n",
    "    return metrics.f1_score(y_test, pred_one)\n",
    "\n",
    "def auc_roc(y_test, pred_scores):\n",
    "    '''\n",
    "    This function calculates the area under the ROC curve\n",
    "    \n",
    "    y_test: real labels\n",
    "    pred_scores: prediction scores\n",
    "    \n",
    "    returns auc\n",
    "    '''\n",
    "    \n",
    "    return metrics.roc_auc_score(y_test, pred_scores)\n",
    "\n",
    "def plot_precision_recall(y_test, pred_scores):\n",
    "    '''\n",
    "    This function plots the precision recall curve\n",
    "    \n",
    "    y_test: true labels\n",
    "    pred_scores: predicted scores\n",
    "    \n",
    "    return: none\n",
    "    '''\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, pred_scores)\n",
    "    plt.pyplot.plot(recall, precision, marker='.')\n",
    "    plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_pipeline as pp\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import monthdelta as md\n",
    "file = './data/projects_2012_2013.csv'\n",
    "df = pp.load_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_pipeline as pp\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import monthdelta as md\n",
    "file = './data/projects_2012_2013.csv'\n",
    "df = pp.load_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for hw3 specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_datetime(df, tgt_col):\n",
    "    '''\n",
    "    Turn column values into datetime\n",
    "    \n",
    "    df: dataframe\n",
    "    tgt_col: column name\n",
    "    \n",
    "    returns pandas series with datetime\n",
    "    '''\n",
    "    return pd.to_datetime(df[tgt_col])\n",
    "\n",
    "def create_label(df, pred_time = 60, pred_unit = 'day'):\n",
    "    '''\n",
    "    This function creates a label column in the dataset given a time horizon\n",
    "    \n",
    "    df: dataframe\n",
    "    pred_time: prediction time horizon\n",
    "    pred_unit: unit of time of prediction (i.e. day or month or year)\n",
    "    \n",
    "    return dataframe\n",
    "    '''\n",
    "    def label(row, pred_time, pred_unit):\n",
    "        if 'day' in pred_unit:\n",
    "            diff = pred_time\n",
    "        elif 'month' in pred_unit:\n",
    "            diff = pred_time * 30 #convert to days\n",
    "        elif 'year' in pred_unit:\n",
    "            diff = pred_time * 365 #convert to days\n",
    "            \n",
    "        if (row.datefullyfunded - row.date_posted).days <= diff:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df['label'] = df.apply(lambda row: label(row, pred_time, pred_unit), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def single_train_test_set(df, feature_cols, label_col, split_col, train_start, train_end, test_end, pred_time, pred_unit = 'day'):\n",
    "    '''\n",
    "    This function builds a single temporal training and test set\n",
    "    \n",
    "    df: dataframe with all data\n",
    "    feature_cols: list of feature columns\n",
    "    label_col: label column string\n",
    "    split_col: column with date to split on\n",
    "    train_start: date to begin training data\n",
    "    train_end: date to end training data\n",
    "    test_end: date to end test data\n",
    "    pred_time: time horizon for predictions (day, month or year)\n",
    "    \n",
    "    returns tuple of x_train, y_train, x_test, y_test\n",
    "    '''\n",
    "    \n",
    "    if 'day' in pred_unit:\n",
    "        actual_train_end = train_end - dt.timedelta(days=pred_time)\n",
    "    elif 'month' in pred_unit:\n",
    "        actual_train_end = train_end - md.monthdelta(pred_time)\n",
    "    elif 'year' in pred_unit.contains:\n",
    "        actual_train_end = dt.datetime(train_end.year - pred_time, train_end.month, train_end.day)\n",
    "        \n",
    "    training_set = df[(df[split_col] >= train_start) & (df[split_col] <= actual_train_end)]\n",
    "    \n",
    "    test_set = df[(df[split_col] >= train_end) & (df[split_col] <= test_end)]\n",
    "    \n",
    "    return (training_set[feature_cols], training_set[label_col], test_set[feature_cols], test_set[label_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert date columns to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date_posted = pp.col_datetime(df, 'date_posted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.datefullyfunded = pp.col_datetime(df,'datefullyfunded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pp.create_label(df, pred_time=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_charter</th>\n",
       "      <th>school_magnet</th>\n",
       "      <th>primary_focus_subject</th>\n",
       "      <th>primary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Civics &amp; Government</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state school_metro school_charter school_magnet  \\\n",
       "0           IL        urban              f             f   \n",
       "1           CA        urban              f             f   \n",
       "2           CA        urban              f             f   \n",
       "3           NY        urban              f             t   \n",
       "4           NY     suburban              f             f   \n",
       "\n",
       "  primary_focus_subject   primary_focus_area resource_type    poverty_level  \\\n",
       "0           Mathematics       Math & Science      Supplies  highest poverty   \n",
       "1   Civics & Government     History & Civics         Books  highest poverty   \n",
       "2              Literacy  Literacy & Language    Technology     high poverty   \n",
       "3              Literacy  Literacy & Language         Books     high poverty   \n",
       "4              Literacy  Literacy & Language    Technology     high poverty   \n",
       "\n",
       "     grade_level  total_price_including_optional_support  students_reached  \\\n",
       "0  Grades PreK-2                                 1498.61              31.0   \n",
       "1     Grades 3-5                                  282.47              28.0   \n",
       "2     Grades 3-5                                 1012.38              56.0   \n",
       "3  Grades PreK-2                                  175.33              23.0   \n",
       "4  Grades PreK-2                                 3591.11             150.0   \n",
       "\n",
       "  eligible_double_your_impact_match  \n",
       "0                                 f  \n",
       "1                                 t  \n",
       "2                                 f  \n",
       "3                                 f  \n",
       "4                                 f  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols=['school_state', 'school_metro','school_charter', 'school_magnet', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'total_price_including_optional_support', 'students_reached', 'eligible_double_your_impact_match']\n",
    "sel = df[feature_cols].copy()\n",
    "sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify feature columns with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_metro\n",
      "primary_focus_subject\n",
      "primary_focus_area\n",
      "resource_type\n",
      "grade_level\n",
      "students_reached\n"
     ]
    }
   ],
   "source": [
    "for x in pp.na_col(df):\n",
    "    if x in feature_cols:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing categorical variables with the most frequent, which is a common way to handle missing categorical data without more information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['school_metro','primary_focus_subject','primary_focus_area','resource_type','grade_level']\n",
    "for x in cat_cols:\n",
    "    sel = pp.na_fill_col(sel, x , most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing numerical variable (students_reached) with the median value because there are outliers affecting the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10       18.0\n",
       "0.25       23.0\n",
       "0.50       30.0\n",
       "0.75      100.0\n",
       "0.90      200.0\n",
       "0.98      700.0\n",
       "1.00    12143.0\n",
       "Name: students_reached, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.students_reached.quantile([0.1, 0.25, 0.5, 0.75, 0.9,0.98,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_state                                               PA\n",
       "school_metro                                         suburban\n",
       "school_charter                                              t\n",
       "school_magnet                                               f\n",
       "primary_focus_subject                                Literacy\n",
       "primary_focus_area                        Literacy & Language\n",
       "resource_type                                      Technology\n",
       "poverty_level                                 highest poverty\n",
       "grade_level                                     Grades PreK-2\n",
       "total_price_including_optional_support                 718.59\n",
       "students_reached                                           30\n",
       "eligible_double_your_impact_match                           f\n",
       "Name: 1816, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = pp.na_fill_col(sel, 'students_reached', np.nanmedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretize numeric features and then get all dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_state                                       object\n",
       "school_metro                                       object\n",
       "school_charter                                     object\n",
       "school_magnet                                      object\n",
       "primary_focus_subject                              object\n",
       "primary_focus_area                                 object\n",
       "resource_type                                      object\n",
       "poverty_level                                      object\n",
       "grade_level                                        object\n",
       "eligible_double_your_impact_match                  object\n",
       "total_price_including_optional_support_binned    category\n",
       "students_reached_binned                          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# discretize numeric features\n",
    "bucketdict= {'total_price_including_optional_support': 4, 'students_reached':4}\n",
    "df_discr = pp.feat_mult_disc(sel, bucketdict, qt=True)\n",
    "\n",
    "df_discr.total_price_including_optional_support_binned.unique()\n",
    "df_discr.students_reached_binned.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state_AK</th>\n",
       "      <th>school_state_AL</th>\n",
       "      <th>school_state_AR</th>\n",
       "      <th>school_state_AZ</th>\n",
       "      <th>school_state_CA</th>\n",
       "      <th>school_state_CO</th>\n",
       "      <th>school_state_CT</th>\n",
       "      <th>school_state_DC</th>\n",
       "      <th>school_state_DE</th>\n",
       "      <th>school_state_FL</th>\n",
       "      <th>...</th>\n",
       "      <th>eligible_double_your_impact_match_f</th>\n",
       "      <th>eligible_double_your_impact_match_t</th>\n",
       "      <th>total_price_including_optional_support_binned_(91.999, 345.81]</th>\n",
       "      <th>total_price_including_optional_support_binned_(345.81, 510.5]</th>\n",
       "      <th>total_price_including_optional_support_binned_(510.5, 752.96]</th>\n",
       "      <th>total_price_including_optional_support_binned_(752.96, 164382.84]</th>\n",
       "      <th>students_reached_binned_(0.999, 23.0]</th>\n",
       "      <th>students_reached_binned_(23.0, 30.0]</th>\n",
       "      <th>students_reached_binned_(30.0, 100.0]</th>\n",
       "      <th>students_reached_binned_(100.0, 12143.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_state_AK  school_state_AL  school_state_AR  school_state_AZ  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   school_state_CA  school_state_CO  school_state_CT  school_state_DC  \\\n",
       "0                0                0                0                0   \n",
       "1                1                0                0                0   \n",
       "2                1                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   school_state_DE  school_state_FL  ...  eligible_double_your_impact_match_f  \\\n",
       "0                0                0  ...                                    1   \n",
       "1                0                0  ...                                    0   \n",
       "2                0                0  ...                                    1   \n",
       "3                0                0  ...                                    1   \n",
       "4                0                0  ...                                    1   \n",
       "\n",
       "   eligible_double_your_impact_match_t  \\\n",
       "0                                    0   \n",
       "1                                    1   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   total_price_including_optional_support_binned_(91.999, 345.81]  \\\n",
       "0                                                  0                \n",
       "1                                                  1                \n",
       "2                                                  0                \n",
       "3                                                  1                \n",
       "4                                                  0                \n",
       "\n",
       "   total_price_including_optional_support_binned_(345.81, 510.5]  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   total_price_including_optional_support_binned_(510.5, 752.96]  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   total_price_including_optional_support_binned_(752.96, 164382.84]  \\\n",
       "0                                                  1                   \n",
       "1                                                  0                   \n",
       "2                                                  1                   \n",
       "3                                                  0                   \n",
       "4                                                  1                   \n",
       "\n",
       "   students_reached_binned_(0.999, 23.0]  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      1   \n",
       "4                                      0   \n",
       "\n",
       "   students_reached_binned_(23.0, 30.0]  \\\n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   students_reached_binned_(30.0, 100.0]  \\\n",
       "0                                      1   \n",
       "1                                      0   \n",
       "2                                      1   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   students_reached_binned_(100.0, 12143.0]  \n",
       "0                                         0  \n",
       "1                                         0  \n",
       "2                                         0  \n",
       "3                                         0  \n",
       "4                                         1  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn variables into dummies\n",
    "df_final = pp.feat_binary(df_discr, df_discr.columns)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run variations of models: \n",
    "### Decision trees, KNN, Logistic Regression, Linear SVM, Random forests, Bagging, Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [dt.datetime(2012,1,1), dt.datetime(2012,7,1), dt.datetime(2013,1,1), dt.datetime(2013,7,1), dt.datetime(2014,1,1)]\n",
    "pred_time = 60 #days\n",
    "feature_cols=['school_state', 'school_metro','school_charter', 'school_magnet', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'total_price_including_optional_support', 'students_reached', 'eligible_double_your_impact_match']\n",
    "label_col = 'label'\n",
    "split_col = 'date_posted'\n",
    "seed=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {'type': 'Dtree', 'clf': pp.dtree_score, 'criteria': ['entropy', 'gini'], 'depth': [5,10,15],'min_leaf': [300,500,700], 'seed': seed},\n",
    "    {'type': 'KNN', 'clf': knn_score, 'n': [3,5,15], 'weights': ['uniform','distance'], 'distance_metric':['minkowski'], 'p': [1,2,3,4]},\n",
    "    {'type': 'LR', 'clf': lr_score, 'p': ['l1','l2'], 'c': [0.1, 1.0, 10.0, 100.0], solver = ['liblinear'], 'seed': seed},\n",
    "    {'type': 'SVM', 'clf': linsvc_score, 'p': ['l2'], 'c': [0.1, 1.0, 10.0, 100.0], 'seed': seed}\n",
    "]\n",
    "\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "svm_thresh = [-0.5, 0, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ml_pipeline' has no attribute 'single_train_test_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-6f2f7b25947b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     x_train,y_train,x_test,y_test = pp.single_train_test_set(df_final, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                                           \u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                           \u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ml_pipeline' has no attribute 'single_train_test_set'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(1, len(windows)-1):\n",
    "    train_start = windows[0]\n",
    "    train_end = windows[i]\n",
    "    test_end = windows[i+1]\n",
    "    \n",
    "    #split data\n",
    "    x_train,y_train,x_test,y_test = pp.single_train_test_set(df_final, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          train_start,\n",
    "                                                          train_end, \n",
    "                                                          test_end, \n",
    "                                                          pred_time=pred_time)\n",
    "    \n",
    "    \n",
    "    #run models\n",
    "    for clf in models:\n",
    "        modeltype = clf['type']\n",
    "        func = clf['clf']\n",
    "        if modeltype == 'Dtree':\n",
    "            seed = clf['seed']\n",
    "            for c in clf['criteria']:\n",
    "                for d in clf['depth']:\n",
    "                    for l in clf['min_leaf']:\n",
    "                        #run model\n",
    "                        info = f'criteria: {c}, depth: {d}, min_leaf: {l}, seed: {seed}'\n",
    "                        scores = func(x_train, y_train, x_test, criteria = c, depth = d, min_leaf = l, seed=seed)\n",
    "                        for t in thresholds:\n",
    "                            a = accuracy_at_threshold(y_test, scores, t)\n",
    "                            p = precision_at_threshold(y_test, scores, t)\n",
    "                            r = recall_at_threshold(y_test, scores, t)\n",
    "                            f1 = f1_at_threshold(y_test, scores, t)\n",
    "                            auc = auc_roc(y_test_scores)\n",
    "                            tmp = {'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                   'details': info, 'threshold': t, 'accuracy': a, 'precision': p, 'recall': r, 'f1': f1, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                    \n",
    "        elif modeltype == 'KNN':\n",
    "            for n in clf['n']:\n",
    "                for w in clf['weights']:\n",
    "                    for d in clf['distance_metric']:\n",
    "                        for p in clf['p']:\n",
    "                            info = f'n: {n}, weights: {w}, distance: {d}, p: {p}'\n",
    "                            scores = func(x_train, y_train, x_test, n = n, weights = w, distance_metric = d, p=p)\n",
    "                            for t in thresholds:\n",
    "                                a = accuracy_at_threshold(y_test, scores, t)\n",
    "                                p = precision_at_threshold(y_test, scores, t)\n",
    "                                r = recall_at_threshold(y_test, scores, t)\n",
    "                                f1 = f1_at_threshold(y_test, scores, t)\n",
    "                                auc = auc_roc(y_test_scores)\n",
    "                                tmp = {'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                       'details': info, 'threshold': t, 'accuracy': a, 'precision': p, 'recall': r, 'f1': f1, 'auc': auc}\n",
    "                                results.append(tmp)\n",
    "                            \n",
    "        elif modeltype == 'LR':\n",
    "            seed = clf['seed']\n",
    "            for p in clf['p']:\n",
    "                for c in clf['c']:\n",
    "                    for s in clf['solver']:\n",
    "                        info = f'penalty: {p}, c: {c}, solver: {s}, seed: {seed}'\n",
    "                        scores = func(x_train, y_train, x_test, p = p, c = c, solver = s, seed=seed)\n",
    "                        for t in thresholds:\n",
    "                            a = accuracy_at_threshold(y_test, scores, t)\n",
    "                            p = precision_at_threshold(y_test, scores, t)\n",
    "                            r = recall_at_threshold(y_test, scores, t)\n",
    "                            f1 = f1_at_threshold(y_test, scores, t)\n",
    "                            auc = auc_roc(y_test_scores)\n",
    "                            tmp = {'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                   'details': info, 'threshold': t, 'accuracy': a, 'precision': p, 'recall': r, 'f1': f1, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                        \n",
    "        elif modeltype == 'SVM':\n",
    "            seed = clf['seed']\n",
    "            for p in clf['p']:\n",
    "                for c in clf['c']:\n",
    "                    info = f'penalty: {p}, c: {c}, seed: {seed}'\n",
    "                    scores = func(x_train, y_train, x_test, p =p, c=c, seed=seed)\n",
    "                    for t in svm_thresh:\n",
    "                            a = accuracy_at_threshold(y_test, scores, t)\n",
    "                            p = precision_at_threshold(y_test, scores, t)\n",
    "                            r = recall_at_threshold(y_test, scores, t)\n",
    "                            f1 = f1_at_threshold(y_test, scores, t)\n",
    "                            auc = auc_roc(y_test_scores)\n",
    "                            tmp = {'train_set_num': i, 'train_start': train_start, 'test_start': train_end,'type': modeltype, \n",
    "                                   'details': info, 'threshold': t, 'accuracy': a, 'precision': p, 'recall': r, 'f1': f1, 'auc': auc}\n",
    "                            results.append(tmp)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use temporal validation to split into training/test sets\n",
    "\n",
    "\n",
    "\n",
    "x_train1,y_train1,x_test1,y_test1 = pp.single_train_test_set(df, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          windows[0],\n",
    "                                                          windows[1], \n",
    "                                                          windows[2], \n",
    "                                                          pred_time=60)\n",
    "\n",
    "x_train2, y_train2, x_test2, y_test2 = pp.single_train_test_set(df, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          windows[0],\n",
    "                                                          windows[2], \n",
    "                                                          windows[3], \n",
    "                                                          pred_time=60)\n",
    "\n",
    "x_train3, y_train3, x_test3, y_test3 = pp.single_train_test_set(df, \n",
    "                                                          feature_cols, \n",
    "                                                          label_col, \n",
    "                                                          split_col, \n",
    "                                                          windows[0],\n",
    "                                                          windows[3], \n",
    "                                                          windows[4], \n",
    "                                                          pred_time=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
